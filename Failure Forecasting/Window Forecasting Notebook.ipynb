{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook Info\n",
    "\n",
    "This Notebook, is for the development of a window forecasting model. The following tables/schemas are considered\n",
    "\n",
    "```\n",
    "Main Database: oasis-prod\n",
    "\n",
    "For Failures:\n",
    "schema: analysis\n",
    "table: failure_info\n",
    "\n",
    "For Features:\n",
    "schema: xspoc\n",
    "table: xdiag\n",
    "\n",
    "Columns used as Features:\n",
    "- PPRL\n",
    "- MPRL\n",
    "- FluidLoadonPump\n",
    "- PumpIntakePressure\n",
    "\n",
    "```\n",
    "\n",
    "**Notes**\n",
    "\n",
    "Following Are some Conditions and Assumption made:\n",
    "\n",
    "- **NAN Values are not handled**. They are dropped for traininng and predictions\n",
    "- A failure specific variable window is used for predictions? \n",
    "- **Failure Data Points are not used** for training and Predictions\n",
    "    - One of the reasons being, we want to see the trends pointing towards the failures and not the actual failures\n",
    "    - Many a time, when failures occur a well is shutdown and no values are present. Dropping them will help us avoid worrying about imputing the data\n",
    "    - At first glance this may not impact the algo\n",
    "    - Further Discussion is needed\n",
    "- Multi-Class Classification is performed (Not MultiLabel)\n",
    "- Training Data\n",
    "    - Do we train on the entire dataset or only where failures have occured\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from library import lib_aws, lib_cleaning\n",
    "from library.lib_metrics import MultiClassMetrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Data\n",
    "\n",
    "Following steps are performed\n",
    "- Import failures (analysis.failure_info)\n",
    "- Import features/data (xspoc.xdiag)\n",
    "- Merge the info\n",
    "- Clean and modify the data depending on how we want the input features\n",
    "\n",
    "**Note: Use `Feature Analysis.ipynb` to analyse the data and failures**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Failures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to oasis-prod DataBase\n",
      "Connection Closed\n",
      "Wall time: 14.6 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NodeID</th>\n",
       "      <th>Last Oil</th>\n",
       "      <th>Finish Date</th>\n",
       "      <th>Job Bucket</th>\n",
       "      <th>Job Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aagvik 1-35H</td>\n",
       "      <td>2019-11-27</td>\n",
       "      <td>2019-12-06</td>\n",
       "      <td>TUBING</td>\n",
       "      <td>TUBING LEAK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aagvik 5298 41-35 2TX</td>\n",
       "      <td>2019-05-29</td>\n",
       "      <td>2019-06-25</td>\n",
       "      <td>PUMP</td>\n",
       "      <td>GAS LIFT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Acadia 31-25H</td>\n",
       "      <td>2018-04-11</td>\n",
       "      <td>2018-05-11</td>\n",
       "      <td>TUBING</td>\n",
       "      <td>TUBING LEAK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Acadia 31-25H</td>\n",
       "      <td>2019-03-30</td>\n",
       "      <td>2019-04-16</td>\n",
       "      <td>PUMP</td>\n",
       "      <td>1-1/4\" PUMP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Acklins 6092 12-18H</td>\n",
       "      <td>2019-12-24</td>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>ROD</td>\n",
       "      <td>POLISH ROD BREAK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  NodeID   Last Oil Finish Date Job Bucket          Job Type\n",
       "0           Aagvik 1-35H 2019-11-27  2019-12-06     TUBING       TUBING LEAK\n",
       "1  Aagvik 5298 41-35 2TX 2019-05-29  2019-06-25       PUMP          GAS LIFT\n",
       "2          Acadia 31-25H 2018-04-11  2018-05-11     TUBING       TUBING LEAK\n",
       "3          Acadia 31-25H 2019-03-30  2019-04-16       PUMP       1-1/4\" PUMP\n",
       "4    Acklins 6092 12-18H 2019-12-24  2020-01-03        ROD  POLISH ROD BREAK"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Querying the entire failure info\n",
    "query_failures = \"\"\"\n",
    "SELECT \n",
    "    \"NodeID\",\n",
    "    \"Last Oil\",\n",
    "    \"Finish Date\",\n",
    "    \"Job Bucket\",\n",
    "    \"Job Type\"\n",
    "FROM\n",
    "    analysis.failure_info\n",
    "ORDER BY \"NodeID\";\n",
    "\"\"\"\n",
    "\n",
    "with lib_aws.PostgresRDS(db='oasis-prod', verbose=1) as engine:\n",
    "    failures = pd.read_sql(query_failures, engine, parse_dates=['Last Oil', 'Finish Date'])\n",
    "    \n",
    "failures.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Data\n",
    "\n",
    "- We need to Import the entire dataset.\n",
    "- While testing choose a subset of the wells "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NodeID</th>\n",
       "      <th>Date</th>\n",
       "      <th>PPRL</th>\n",
       "      <th>MPRL</th>\n",
       "      <th>FluidLoadonPump</th>\n",
       "      <th>PumpIntakePressure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aagvik 1-35H</td>\n",
       "      <td>2019-06-21 15:58:34</td>\n",
       "      <td>27639.0</td>\n",
       "      <td>16811.0</td>\n",
       "      <td>3280.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aagvik 1-35H</td>\n",
       "      <td>2019-06-21 16:25:36</td>\n",
       "      <td>27457.0</td>\n",
       "      <td>16752.0</td>\n",
       "      <td>3241.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aagvik 1-35H</td>\n",
       "      <td>2019-06-21 18:25:16</td>\n",
       "      <td>27448.0</td>\n",
       "      <td>16594.0</td>\n",
       "      <td>3330.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aagvik 1-35H</td>\n",
       "      <td>2019-06-21 18:28:10</td>\n",
       "      <td>27424.0</td>\n",
       "      <td>16595.0</td>\n",
       "      <td>3327.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aagvik 1-35H</td>\n",
       "      <td>2019-06-21 20:25:01</td>\n",
       "      <td>27662.0</td>\n",
       "      <td>16711.0</td>\n",
       "      <td>3341.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         NodeID                Date     PPRL     MPRL  FluidLoadonPump  \\\n",
       "0  Aagvik 1-35H 2019-06-21 15:58:34  27639.0  16811.0           3280.0   \n",
       "1  Aagvik 1-35H 2019-06-21 16:25:36  27457.0  16752.0           3241.0   \n",
       "2  Aagvik 1-35H 2019-06-21 18:25:16  27448.0  16594.0           3330.0   \n",
       "3  Aagvik 1-35H 2019-06-21 18:28:10  27424.0  16595.0           3327.0   \n",
       "4  Aagvik 1-35H 2019-06-21 20:25:01  27662.0  16711.0           3341.0   \n",
       "\n",
       "   PumpIntakePressure  \n",
       "0                 NaN  \n",
       "1                 NaN  \n",
       "2                 NaN  \n",
       "3                 NaN  \n",
       "4                 NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failure info in these in these wells\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NodeID</th>\n",
       "      <th>Last Oil</th>\n",
       "      <th>Finish Date</th>\n",
       "      <th>Job Bucket</th>\n",
       "      <th>Job Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anderson 7-18H</td>\n",
       "      <td>2019-10-08</td>\n",
       "      <td>2019-10-16</td>\n",
       "      <td>ROD</td>\n",
       "      <td>POLISH ROD BREAK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Andre 5501 14-5 3B</td>\n",
       "      <td>2018-04-30</td>\n",
       "      <td>2018-05-12</td>\n",
       "      <td>ROD</td>\n",
       "      <td>POLISH ROD BREAK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Andre 5501 14-5 3B</td>\n",
       "      <td>2018-05-22</td>\n",
       "      <td>2018-05-26</td>\n",
       "      <td>ROD</td>\n",
       "      <td>1\" ROD SECTION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Andre 5501 14-5 3B</td>\n",
       "      <td>2020-03-06</td>\n",
       "      <td>2020-03-13</td>\n",
       "      <td>PUMP</td>\n",
       "      <td>1-3/4\" PUMP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Autumn Wind State 5601 14-16B</td>\n",
       "      <td>2020-02-03</td>\n",
       "      <td>2020-02-10</td>\n",
       "      <td>TUBING</td>\n",
       "      <td>TUBING LEAK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Berwick 4-2HE</td>\n",
       "      <td>2019-10-31</td>\n",
       "      <td>2019-11-11</td>\n",
       "      <td>PUMP</td>\n",
       "      <td>2\" PUMP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Carl Federal 2658 43-23H</td>\n",
       "      <td>2019-01-27</td>\n",
       "      <td>2019-02-14</td>\n",
       "      <td>ROD</td>\n",
       "      <td>POLISH ROD BREAK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Carl Federal 2658 43-23H</td>\n",
       "      <td>2019-06-04</td>\n",
       "      <td>2019-07-02</td>\n",
       "      <td>ROD</td>\n",
       "      <td>POLISH ROD BREAK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Carl Federal 2658 43-23H</td>\n",
       "      <td>2020-02-03</td>\n",
       "      <td>2020-02-07</td>\n",
       "      <td>ROD</td>\n",
       "      <td>POLISH ROD BREAK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Carl Federal 2658 43-23H</td>\n",
       "      <td>2019-07-26</td>\n",
       "      <td>2019-08-13</td>\n",
       "      <td>ROD</td>\n",
       "      <td>1\" ROD SECTION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Carl Federal 2658 43-23H</td>\n",
       "      <td>2018-06-22</td>\n",
       "      <td>2018-07-18</td>\n",
       "      <td>ROD</td>\n",
       "      <td>POLISH ROD BREAK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Carson Federal 2658 13-17H</td>\n",
       "      <td>2020-05-21</td>\n",
       "      <td>2020-06-19</td>\n",
       "      <td>TUBING</td>\n",
       "      <td>TUBING LEAK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Carson Federal 2658 13-17H</td>\n",
       "      <td>2018-03-26</td>\n",
       "      <td>2018-04-06</td>\n",
       "      <td>PUMP</td>\n",
       "      <td>2\" PUMP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Cook 5300 12-13 6B</td>\n",
       "      <td>2019-12-13</td>\n",
       "      <td>2019-12-19</td>\n",
       "      <td>TUBING</td>\n",
       "      <td>TUBING LEAK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Dixon 5602 44-34H</td>\n",
       "      <td>2019-09-06</td>\n",
       "      <td>2019-09-19</td>\n",
       "      <td>ROD</td>\n",
       "      <td>POLISH ROD BREAK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Dixon 5602 44-34H</td>\n",
       "      <td>2019-01-21</td>\n",
       "      <td>2019-03-01</td>\n",
       "      <td>PUMP</td>\n",
       "      <td>1-3/4\" PUMP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Dixon 5602 44-34H</td>\n",
       "      <td>2017-12-27</td>\n",
       "      <td>2018-01-20</td>\n",
       "      <td>PUMP</td>\n",
       "      <td>1-1/2\" PUMP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Emma 13-7H</td>\n",
       "      <td>2020-04-21</td>\n",
       "      <td>2020-06-12</td>\n",
       "      <td>PUMP</td>\n",
       "      <td>1-1/2\" PUMP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Forland 28-33H</td>\n",
       "      <td>2018-12-17</td>\n",
       "      <td>2018-12-24</td>\n",
       "      <td>TUBING</td>\n",
       "      <td>TUBING LEAK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Forland 28-33H</td>\n",
       "      <td>2018-06-12</td>\n",
       "      <td>2018-07-14</td>\n",
       "      <td>PUMP</td>\n",
       "      <td>2-3/4 PUMP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Forland 28-33H</td>\n",
       "      <td>2019-07-15</td>\n",
       "      <td>2019-07-24</td>\n",
       "      <td>PUMP</td>\n",
       "      <td>1-3/4\" PUMP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Forland 28-33H</td>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>2018-01-06</td>\n",
       "      <td>PUMP</td>\n",
       "      <td>2-3/4 PUMP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Johnsrud 5198 12-18 10T</td>\n",
       "      <td>2020-03-03</td>\n",
       "      <td>2020-03-11</td>\n",
       "      <td>TUBING</td>\n",
       "      <td>TUBING LEAK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Johnsrud 5198 12-18 10T</td>\n",
       "      <td>2019-07-18</td>\n",
       "      <td>2019-08-01</td>\n",
       "      <td>PUMP</td>\n",
       "      <td>2\" PUMP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Mae 5603 43-19H</td>\n",
       "      <td>2020-02-01</td>\n",
       "      <td>2020-02-10</td>\n",
       "      <td>PUMP</td>\n",
       "      <td>1-1/2\" PUMP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Susie 15-22H</td>\n",
       "      <td>2020-02-15</td>\n",
       "      <td>2020-02-25</td>\n",
       "      <td>ROD</td>\n",
       "      <td>1\" ROD SECTION</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           NodeID   Last Oil Finish Date Job Bucket  \\\n",
       "0                  Anderson 7-18H 2019-10-08  2019-10-16        ROD   \n",
       "1              Andre 5501 14-5 3B 2018-04-30  2018-05-12        ROD   \n",
       "2              Andre 5501 14-5 3B 2018-05-22  2018-05-26        ROD   \n",
       "3              Andre 5501 14-5 3B 2020-03-06  2020-03-13       PUMP   \n",
       "4   Autumn Wind State 5601 14-16B 2020-02-03  2020-02-10     TUBING   \n",
       "5                   Berwick 4-2HE 2019-10-31  2019-11-11       PUMP   \n",
       "6        Carl Federal 2658 43-23H 2019-01-27  2019-02-14        ROD   \n",
       "7        Carl Federal 2658 43-23H 2019-06-04  2019-07-02        ROD   \n",
       "8        Carl Federal 2658 43-23H 2020-02-03  2020-02-07        ROD   \n",
       "9        Carl Federal 2658 43-23H 2019-07-26  2019-08-13        ROD   \n",
       "10       Carl Federal 2658 43-23H 2018-06-22  2018-07-18        ROD   \n",
       "11     Carson Federal 2658 13-17H 2020-05-21  2020-06-19     TUBING   \n",
       "12     Carson Federal 2658 13-17H 2018-03-26  2018-04-06       PUMP   \n",
       "13             Cook 5300 12-13 6B 2019-12-13  2019-12-19     TUBING   \n",
       "14              Dixon 5602 44-34H 2019-09-06  2019-09-19        ROD   \n",
       "15              Dixon 5602 44-34H 2019-01-21  2019-03-01       PUMP   \n",
       "16              Dixon 5602 44-34H 2017-12-27  2018-01-20       PUMP   \n",
       "17                     Emma 13-7H 2020-04-21  2020-06-12       PUMP   \n",
       "18                 Forland 28-33H 2018-12-17  2018-12-24     TUBING   \n",
       "19                 Forland 28-33H 2018-06-12  2018-07-14       PUMP   \n",
       "20                 Forland 28-33H 2019-07-15  2019-07-24       PUMP   \n",
       "21                 Forland 28-33H 2018-01-04  2018-01-06       PUMP   \n",
       "22        Johnsrud 5198 12-18 10T 2020-03-03  2020-03-11     TUBING   \n",
       "23        Johnsrud 5198 12-18 10T 2019-07-18  2019-08-01       PUMP   \n",
       "24                Mae 5603 43-19H 2020-02-01  2020-02-10       PUMP   \n",
       "25                   Susie 15-22H 2020-02-15  2020-02-25        ROD   \n",
       "\n",
       "            Job Type  \n",
       "0   POLISH ROD BREAK  \n",
       "1   POLISH ROD BREAK  \n",
       "2     1\" ROD SECTION  \n",
       "3        1-3/4\" PUMP  \n",
       "4        TUBING LEAK  \n",
       "5            2\" PUMP  \n",
       "6   POLISH ROD BREAK  \n",
       "7   POLISH ROD BREAK  \n",
       "8   POLISH ROD BREAK  \n",
       "9     1\" ROD SECTION  \n",
       "10  POLISH ROD BREAK  \n",
       "11       TUBING LEAK  \n",
       "12           2\" PUMP  \n",
       "13       TUBING LEAK  \n",
       "14  POLISH ROD BREAK  \n",
       "15       1-3/4\" PUMP  \n",
       "16       1-1/2\" PUMP  \n",
       "17       1-1/2\" PUMP  \n",
       "18       TUBING LEAK  \n",
       "19        2-3/4 PUMP  \n",
       "20       1-3/4\" PUMP  \n",
       "21        2-3/4 PUMP  \n",
       "22       TUBING LEAK  \n",
       "23           2\" PUMP  \n",
       "24       1-1/2\" PUMP  \n",
       "25    1\" ROD SECTION  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# List of wells for testing\n",
    "well_list = [\n",
    "    'Anderson 7-18H',\n",
    "    'Andre 5501 14-5 3B',\n",
    "    'Autumn Wind State 5601 14-16B',\n",
    "    'Berwick 4-2HE',\n",
    "    'Carl Federal 2658 43-23H',\n",
    "    'Carson Federal 2658 13-17H',\n",
    "    'Cook 5300 12-13 6B',\n",
    "    'Dixon 5602 44-34H',\n",
    "    'Emma 13-7H',\n",
    "    'Forland 28-33H',\n",
    "    'Hanson 33-28H'\n",
    "    'Inez 6093 43-19H',\n",
    "    'Johnsrud 5198 12-18 10T',\n",
    "    'Mae 5603 43-19H',\n",
    "    'Susie 15-22H'\n",
    "]\n",
    "\n",
    "\n",
    "data_query = \"\"\"\n",
    "SELECT\n",
    "    \"NodeID\",\n",
    "    \"Date\",\n",
    "    \"PPRL\",\n",
    "    \"MPRL\",\n",
    "    \"FluidLoadonPump\",\n",
    "    \"PumpIntakePressure\"\n",
    "FROM xspoc.xdiag\n",
    "-- WHERE \"NodeID\" in {}\n",
    "ORDER BY \"NodeID\",\"Date\"\n",
    "\"\"\".format(tuple(well_list))\n",
    "\n",
    "with lib_aws.PostgresRDS(db='oasis-prod') as engine:\n",
    "    data = pd.read_sql(data_query, engine, parse_dates=['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "869"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "well_list = data.NodeID.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NodeID</th>\n",
       "      <th>Date</th>\n",
       "      <th>PPRL</th>\n",
       "      <th>MPRL</th>\n",
       "      <th>FluidLoadonPump</th>\n",
       "      <th>PumpIntakePressure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aagvik 1-35H</td>\n",
       "      <td>2019-06-21 15:58:34</td>\n",
       "      <td>27639.0</td>\n",
       "      <td>16811.0</td>\n",
       "      <td>3280.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aagvik 1-35H</td>\n",
       "      <td>2019-06-21 16:25:36</td>\n",
       "      <td>27457.0</td>\n",
       "      <td>16752.0</td>\n",
       "      <td>3241.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aagvik 1-35H</td>\n",
       "      <td>2019-06-21 18:25:16</td>\n",
       "      <td>27448.0</td>\n",
       "      <td>16594.0</td>\n",
       "      <td>3330.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aagvik 1-35H</td>\n",
       "      <td>2019-06-21 18:28:10</td>\n",
       "      <td>27424.0</td>\n",
       "      <td>16595.0</td>\n",
       "      <td>3327.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aagvik 1-35H</td>\n",
       "      <td>2019-06-21 20:25:01</td>\n",
       "      <td>27662.0</td>\n",
       "      <td>16711.0</td>\n",
       "      <td>3341.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         NodeID                Date     PPRL     MPRL  FluidLoadonPump  \\\n",
       "0  Aagvik 1-35H 2019-06-21 15:58:34  27639.0  16811.0           3280.0   \n",
       "1  Aagvik 1-35H 2019-06-21 16:25:36  27457.0  16752.0           3241.0   \n",
       "2  Aagvik 1-35H 2019-06-21 18:25:16  27448.0  16594.0           3330.0   \n",
       "3  Aagvik 1-35H 2019-06-21 18:28:10  27424.0  16595.0           3327.0   \n",
       "4  Aagvik 1-35H 2019-06-21 20:25:01  27662.0  16711.0           3341.0   \n",
       "\n",
       "   PumpIntakePressure  \n",
       "0                 NaN  \n",
       "1                 NaN  \n",
       "2                 NaN  \n",
       "3                 NaN  \n",
       "4                 NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failure info in these in these wells\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NodeID</th>\n",
       "      <th>Last Oil</th>\n",
       "      <th>Finish Date</th>\n",
       "      <th>Job Bucket</th>\n",
       "      <th>Job Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aagvik 1-35H</td>\n",
       "      <td>2019-11-27</td>\n",
       "      <td>2019-12-06</td>\n",
       "      <td>TUBING</td>\n",
       "      <td>TUBING LEAK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Acadia 31-25H</td>\n",
       "      <td>2018-04-11</td>\n",
       "      <td>2018-05-11</td>\n",
       "      <td>TUBING</td>\n",
       "      <td>TUBING LEAK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Acadia 31-25H</td>\n",
       "      <td>2019-03-30</td>\n",
       "      <td>2019-04-16</td>\n",
       "      <td>PUMP</td>\n",
       "      <td>1-1/4\" PUMP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aerabelle 5502 43-7T</td>\n",
       "      <td>2018-10-10</td>\n",
       "      <td>2018-10-24</td>\n",
       "      <td>PUMP</td>\n",
       "      <td>1-1/2\" PUMP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aerabelle 5502 43-7T</td>\n",
       "      <td>2018-10-10</td>\n",
       "      <td>2019-08-15</td>\n",
       "      <td>ROD</td>\n",
       "      <td>3/4\" ROD SECTION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>782</th>\n",
       "      <td>Yeiser 5603 42-33H</td>\n",
       "      <td>2020-06-13</td>\n",
       "      <td>2020-06-25</td>\n",
       "      <td>TUBING</td>\n",
       "      <td>TUBING LEAK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>783</th>\n",
       "      <td>Yeiser 5603 42-33H</td>\n",
       "      <td>2019-06-12</td>\n",
       "      <td>2019-06-29</td>\n",
       "      <td>PUMP</td>\n",
       "      <td>1-1/2\" PUMP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>784</th>\n",
       "      <td>Zdenek 6093 42-24H</td>\n",
       "      <td>2018-09-18</td>\n",
       "      <td>2018-09-29</td>\n",
       "      <td>ROD</td>\n",
       "      <td>POLISH ROD BREAK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785</th>\n",
       "      <td>Zdenek 6093 42-24H</td>\n",
       "      <td>2020-04-09</td>\n",
       "      <td>2020-05-08</td>\n",
       "      <td>PUMP</td>\n",
       "      <td>1-3/4\" PUMP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>786</th>\n",
       "      <td>Zdenek 6093 42-24H</td>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>2018-01-26</td>\n",
       "      <td>PUMP</td>\n",
       "      <td>1-1/2\" PUMP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>787 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   NodeID   Last Oil Finish Date Job Bucket          Job Type\n",
       "0            Aagvik 1-35H 2019-11-27  2019-12-06     TUBING       TUBING LEAK\n",
       "1           Acadia 31-25H 2018-04-11  2018-05-11     TUBING       TUBING LEAK\n",
       "2           Acadia 31-25H 2019-03-30  2019-04-16       PUMP       1-1/4\" PUMP\n",
       "3    Aerabelle 5502 43-7T 2018-10-10  2018-10-24       PUMP       1-1/2\" PUMP\n",
       "4    Aerabelle 5502 43-7T 2018-10-10  2019-08-15        ROD  3/4\" ROD SECTION\n",
       "..                    ...        ...         ...        ...               ...\n",
       "782    Yeiser 5603 42-33H 2020-06-13  2020-06-25     TUBING       TUBING LEAK\n",
       "783    Yeiser 5603 42-33H 2019-06-12  2019-06-29       PUMP       1-1/2\" PUMP\n",
       "784    Zdenek 6093 42-24H 2018-09-18  2018-09-29        ROD  POLISH ROD BREAK\n",
       "785    Zdenek 6093 42-24H 2020-04-09  2020-05-08       PUMP       1-3/4\" PUMP\n",
       "786    Zdenek 6093 42-24H 2018-01-02  2018-01-26       PUMP       1-1/2\" PUMP\n",
       "\n",
       "[787 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Failur Info only from wells present in the data\n",
    "failure_info = failures[failures.NodeID.isin(well_list)]\n",
    "failure_info.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# info\n",
    "display(data.head())\n",
    "print(\"Failure info in these in these wells\")\n",
    "display(failure_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Before analysing the data we need to merge the information\n",
    "Transfering info from failures to data (copy of features)\n",
    "Using a for loop -- may not be very efficient\n",
    "\"\"\"\n",
    "\n",
    "def fill_null(df, chk_col='PPRL', well_col='NodeID', time_col='Date'):\n",
    "    \"\"\"\n",
    "    This function will fill in Null Values on those dates where no datapoints are present\n",
    "    Helps Show failures where no data was present\n",
    "    Will have to take this into account when running analysis \n",
    "    \"\"\"\n",
    "    data_temp = df.copy()\n",
    "    # Set time col as index if it is not\n",
    "    if time_col in data_temp.columns:\n",
    "        data_temp.set_index(time_col, inplace=True)\n",
    "    \n",
    "    data_gp = data_temp.groupby(well_col).resample('1D').max()  # Groupby wellname and resample to Day freq\n",
    "    data_gp.drop(columns=[well_col], inplace=True)  # Drop these columns as they are present in the index\n",
    "    data_gp.reset_index(inplace=True)  # Get Back WellCol from\n",
    "    data_null = data_gp[data_gp.loc[:, chk_col].isnull()]  # Get all null values, which need to be added to the main data file\n",
    "    data_null.reset_index(inplace=True, drop=True)\n",
    "    data_temp.reset_index(inplace=True)  # get timestamp back in the column for concating\n",
    "    data_full = pd.concat([data_temp, data_null], axis=0, ignore_index=True)  # concat null and og files\n",
    "    data_full.sort_values(by=[well_col, time_col], inplace=True)\n",
    "    data_full.drop_duplicates(subset=[well_col, time_col], inplace=True)\n",
    "    data_full.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    return data_full\n",
    "\n",
    "def failure_merge(df, failure_df, transfer_cols):\n",
    "    \"\"\"\n",
    "    Merges the failures info\n",
    "    :param df: dataframe to which info is being transferred to. (Should have columns \"NodeID\" and \"Date\")\n",
    "    :param failure_df: Failure info data (Should have columns \"NodeID\", \"Start Date\" and \"End Data\")\n",
    "    :param cols: Columns which need to be transferred\n",
    "    \"\"\"\n",
    "    merged = df.copy()  \n",
    "    for col in transfer_cols:\n",
    "        merged[col] = 'Normal'  # for now putting everything as normal (even NAN's)\n",
    "        \n",
    "    for i in failure_df.index:\n",
    "        well = failure_df.loc[i, 'NodeID']\n",
    "        t_start = failure_df.loc[i, 'Last Oil']\n",
    "        t_end = failure_df.loc[i, 'Finish Date'] + pd.Timedelta('1 day')  # As we have day based frequency (the times in a day are considered as 00:00:00)\n",
    "        bool_ = (merged.NodeID == well) & (merged.Date >= t_start) & (merged.Date <= t_end)  # Boolean mask for main data\n",
    "        merged.loc[bool_, transfer_cols] = failure_df.loc[i, transfer_cols].values\n",
    "        \n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 54s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>NodeID</th>\n",
       "      <th>PPRL</th>\n",
       "      <th>MPRL</th>\n",
       "      <th>FluidLoadonPump</th>\n",
       "      <th>PumpIntakePressure</th>\n",
       "      <th>Job Bucket</th>\n",
       "      <th>Job Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-06-21 15:58:34</td>\n",
       "      <td>Aagvik 1-35H</td>\n",
       "      <td>27639.0</td>\n",
       "      <td>16811.0</td>\n",
       "      <td>3280.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-06-21 16:25:36</td>\n",
       "      <td>Aagvik 1-35H</td>\n",
       "      <td>27457.0</td>\n",
       "      <td>16752.0</td>\n",
       "      <td>3241.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-06-21 18:25:16</td>\n",
       "      <td>Aagvik 1-35H</td>\n",
       "      <td>27448.0</td>\n",
       "      <td>16594.0</td>\n",
       "      <td>3330.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-06-21 18:28:10</td>\n",
       "      <td>Aagvik 1-35H</td>\n",
       "      <td>27424.0</td>\n",
       "      <td>16595.0</td>\n",
       "      <td>3327.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-06-21 20:25:01</td>\n",
       "      <td>Aagvik 1-35H</td>\n",
       "      <td>27662.0</td>\n",
       "      <td>16711.0</td>\n",
       "      <td>3341.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Date        NodeID     PPRL     MPRL  FluidLoadonPump  \\\n",
       "0 2019-06-21 15:58:34  Aagvik 1-35H  27639.0  16811.0           3280.0   \n",
       "1 2019-06-21 16:25:36  Aagvik 1-35H  27457.0  16752.0           3241.0   \n",
       "2 2019-06-21 18:25:16  Aagvik 1-35H  27448.0  16594.0           3330.0   \n",
       "3 2019-06-21 18:28:10  Aagvik 1-35H  27424.0  16595.0           3327.0   \n",
       "4 2019-06-21 20:25:01  Aagvik 1-35H  27662.0  16711.0           3341.0   \n",
       "\n",
       "   PumpIntakePressure Job Bucket Job Type  \n",
       "0                 NaN     Normal   Normal  \n",
       "1                 NaN     Normal   Normal  \n",
       "2                 NaN     Normal   Normal  \n",
       "3                 NaN     Normal   Normal  \n",
       "4                 NaN     Normal   Normal  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "data = fill_null(data)  # FIlling in Nan's where data was missing\n",
    "\n",
    "# Transfer 'Job Bucket' from failure_info to fill_data\n",
    "transfer_col = ['Job Bucket', 'Job Type']\n",
    "data = failure_merge(data, failure_info, transfer_col)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engg\n",
    "\n",
    "Depending on What features we and labels we want to use for our model, we can use the functions\n",
    "\n",
    "`get_agg()`:\n",
    "\n",
    "    - For now only gives us moving averages\n",
    "    - Can modify it to give other aggregate functions\n",
    "    \n",
    "`create_prediction_zones()`:\n",
    "    \n",
    "    - Will create new classes depending on what windows we choose for failures\n",
    "  \n",
    "**Note: Both these fucntions will give out separate dataframes/series and will have to be merged accordingly**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Helper Functions\n",
    "\"\"\"\n",
    "\n",
    "def get_agg(df, freq, time_col='Date', well_col = 'NodeID'):\n",
    "    \n",
    "    frames = []\n",
    "    \n",
    "    for well in df[well_col].unique():\n",
    "        temp_df = df[df[well_col] == well].copy()\n",
    "        temp_df.set_index(time_col, inplace=True)\n",
    "        temp_df = temp_df.rolling(freq).mean()\n",
    "        temp_df = temp_df.add_prefix(freq+'_')\n",
    "        temp_df[well_col] = well\n",
    "        temp_df.reset_index(inplace=True)\n",
    "        frames.append(temp_df)\n",
    "        \n",
    "    rolled_df = pd.concat(frames)\n",
    "    rolled_df.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "    return rolled_df\n",
    "\n",
    "\n",
    "def create_prediction_zones(df, fail_col, prediction_zone_dict):\n",
    "    \"\"\"\n",
    "    Depending on the prediction_zone_dict will create predictions zones for failures \n",
    "    in the Failure column.\n",
    "    :param df: The dataframe to extract it from\n",
    "    :param fail_col: Failure column to use from the dataframe\n",
    "    :param prediction_zone_dict: A dict with timedeltas for each type of Failure in fail_col\n",
    "    :return Will return a Series or an Array of these Prediction Zones\n",
    "    \"\"\"\n",
    "    \n",
    "    test_data = df[['NodeID', 'Date', fail_col]].copy()\n",
    "    fail_zones = test_data[fail_col]  # fail_zones will be initialized as a copy of the fail col\n",
    "    \n",
    "    # Getting start of predictions from fail col\n",
    "    fail_dates = test_data[test_data[fail_col] != 'Normal']  # everthing other than normal is considered as a prediction\n",
    "    fail_start = fail_dates[fail_dates.Date.diff().abs().fillna(pd.Timedelta('10D')) > pd.Timedelta('1d 12H')]\n",
    "    fail_start.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "    # Adding zones by iterating over each prediction start date\n",
    "    for i in fail_start.index:\n",
    "        temp_well = fail_start.loc[i, 'NodeID']  # well name\n",
    "        zone_end_date = fail_start.loc[i, 'Date']  # prediction start date\n",
    "        fail = fail_start.loc[i, fail_col]  # actual prediction class\n",
    "        zone_delta = pd.Timedelta(prediction_zone_dict[fail])  # delta to subtract from the dictionary\n",
    "        zone_start_date = zone_end_date - zone_delta\n",
    "\n",
    "        bool_ = (test_data.NodeID == temp_well) & (test_data.Date < zone_end_date) & (test_data.Date >= zone_start_date)\n",
    "        fail_zones[bool_] = 'fz_' + fail\n",
    "        \n",
    "    return fail_zones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Say we want to use rolling averages with a frequency of 7 days for our features and a constant 10 day window for our failures. Follow the next few sections to see how it will be done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\rai_v\\onedrive\\python coursera\\oasis\\venv\\lib\\site-packages\\ipykernel_launcher.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "#  # 7 day rolling averages\n",
    "# avg_data = get_agg(df=data, freq='7D')  \n",
    "\n",
    "# # Merge it with the original data \n",
    "# # and use only those columns which will be of use\n",
    "# # While working with large datasets try optmizing the copies of dataframes you create\n",
    "# # May not even have to merge it\n",
    "\n",
    "# full_data = data.set_index(['NodeID', 'Date']).merge(avg_data.set_index(['NodeID', 'Date']), \n",
    "#                                                      left_index=True,\n",
    "#                                                      right_index=True).reset_index()\n",
    "\n",
    "# # Drop Columns that we dont need\n",
    "# cols_drop = [\n",
    "#     'PPRL',\n",
    "#     'MPRL',\n",
    "#     'PumpIntakePressure',\n",
    "#     'FluidLoadonPump',\n",
    "#     'Job Type'\n",
    "# ]\n",
    "\n",
    "# full_data.drop(columns=cols_drop, inplace=True)\n",
    "\n",
    "# Create pred windows\n",
    "# Note:  The output of the fucntion will be a pandas Series\n",
    "pred_zone_dict = {\n",
    "    'PUMP': '15 days',\n",
    "    'ROD': '15 days',\n",
    "    'TUBING': '15 days',\n",
    "    'BHA': '10 days'\n",
    "}\n",
    "\n",
    "full_data['Label'] = create_prediction_zones(df=full_data, \n",
    "                                             fail_col='Job Bucket', \n",
    "                                             prediction_zone_dict=pred_zone_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some Assumtions we are going to make:\n",
    "- Drop Nan values\n",
    "- Remove the actual failures as classes and only use windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data.dropna(inplace=True)\n",
    "\n",
    "class_drop = ['PUMP', 'ROD', 'TUBING', 'BHA']\n",
    "full_data = full_data[~full_data.Label.isin(class_drop)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>7D_PPRL</th>\n",
       "      <th>7D_MPRL</th>\n",
       "      <th>7D_FluidLoadonPump</th>\n",
       "      <th>7D_PumpIntakePressure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>31488.000000</td>\n",
       "      <td>17075.000000</td>\n",
       "      <td>9968.00</td>\n",
       "      <td>608.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>31488.000000</td>\n",
       "      <td>17075.000000</td>\n",
       "      <td>9968.00</td>\n",
       "      <td>608.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>31613.000000</td>\n",
       "      <td>17062.500000</td>\n",
       "      <td>9915.00</td>\n",
       "      <td>611.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>31615.333333</td>\n",
       "      <td>17012.666667</td>\n",
       "      <td>10011.00</td>\n",
       "      <td>564.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>31594.500000</td>\n",
       "      <td>17021.250000</td>\n",
       "      <td>9975.25</td>\n",
       "      <td>576.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          7D_PPRL       7D_MPRL  7D_FluidLoadonPump  7D_PumpIntakePressure\n",
       "128  31488.000000  17075.000000             9968.00             608.000000\n",
       "129  31488.000000  17075.000000             9968.00             608.000000\n",
       "130  31613.000000  17062.500000             9915.00             611.000000\n",
       "131  31615.333333  17012.666667            10011.00             564.666667\n",
       "132  31594.500000  17021.250000             9975.25             576.500000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes Being Predicted\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Normal       3080729\n",
       "fz_PUMP        12220\n",
       "fz_ROD         11512\n",
       "fz_TUBING       9485\n",
       "fz_BHA           340\n",
       "Name: Label, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = full_data.drop(columns=['NodeID', 'Date', 'Job Bucket', 'Label'])\n",
    "Y = full_data.Label\n",
    "\n",
    "print(\"Features\")\n",
    "display(X.head())\n",
    "\n",
    "print(\"Classes Being Predicted\")\n",
    "display(Y.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Algos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Model 1\n",
    "Random Forest classifier\n",
    "\"\"\"\n",
    "\n",
    "def build_rfc_model():\n",
    "    \"\"\"\n",
    "    Define A Random Forrest Classifier Model\n",
    "    :return: RFC Model\n",
    "    \"\"\"\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    rfc_params = {\n",
    "        'n_estimators': 100,\n",
    "        'min_samples_split': 2,\n",
    "        'min_samples_leaf': 1,\n",
    "        'class_weight': 'balanced',\n",
    "        'verbose': 0,\n",
    "        'max_features': 'auto',\n",
    "        'max_depth': None,\n",
    "    }\n",
    "\n",
    "    rfc = RandomForestClassifier(**rfc_params)\n",
    "\n",
    "    model = Pipeline([\n",
    "        ('scaler', scaler),\n",
    "        ('rfc', rfc)\n",
    "    ])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                ('rfc', RandomForestClassifier(class_weight='balanced'))])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_model = build_rfc_model()\n",
    "rfc_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted Metrics\n",
      "Precision : 99.78\n",
      "Recall: 99.78\n",
      "F-score: 99.77\n",
      "\n",
      "Macro Metrics\n",
      "Precision : 98.33\n",
      "Recall: 82.53\n",
      "F-score: 89.40\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal       1.00      1.00      1.00    924219\n",
      "      fz_BHA       0.99      0.68      0.80       102\n",
      "     fz_PUMP       0.98      0.79      0.88      3666\n",
      "      fz_ROD       0.98      0.86      0.92      3454\n",
      "   fz_TUBING       0.98      0.79      0.88      2845\n",
      "\n",
      "    accuracy                           1.00    934286\n",
      "   macro avg       0.98      0.83      0.89    934286\n",
      "weighted avg       1.00      1.00      1.00    934286\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\rai_v\\onedrive\\python coursera\\oasis\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Metrics\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F-Score_wt</th>\n",
       "      <th>Precision_wt</th>\n",
       "      <th>Recall_wt</th>\n",
       "      <th>F-Score_macro</th>\n",
       "      <th>Precision_macro</th>\n",
       "      <th>Recall_macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>98.270000</td>\n",
       "      <td>97.860000</td>\n",
       "      <td>98.680000</td>\n",
       "      <td>19.89000</td>\n",
       "      <td>20.050000</td>\n",
       "      <td>19.960000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>98.240000</td>\n",
       "      <td>98.010000</td>\n",
       "      <td>98.590000</td>\n",
       "      <td>22.30000</td>\n",
       "      <td>32.750000</td>\n",
       "      <td>21.330000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>98.290000</td>\n",
       "      <td>97.890000</td>\n",
       "      <td>98.700000</td>\n",
       "      <td>20.45000</td>\n",
       "      <td>21.480000</td>\n",
       "      <td>20.310000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>98.266667</td>\n",
       "      <td>97.920000</td>\n",
       "      <td>98.656667</td>\n",
       "      <td>20.88000</td>\n",
       "      <td>24.760000</td>\n",
       "      <td>20.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STD</th>\n",
       "      <td>0.020548</td>\n",
       "      <td>0.064807</td>\n",
       "      <td>0.047842</td>\n",
       "      <td>1.02979</td>\n",
       "      <td>5.679865</td>\n",
       "      <td>0.581167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      F-Score_wt  Precision_wt  Recall_wt  F-Score_macro  Precision_macro  \\\n",
       "0      98.270000     97.860000  98.680000       19.89000        20.050000   \n",
       "1      98.240000     98.010000  98.590000       22.30000        32.750000   \n",
       "2      98.290000     97.890000  98.700000       20.45000        21.480000   \n",
       "Mean   98.266667     97.920000  98.656667       20.88000        24.760000   \n",
       "STD     0.020548      0.064807   0.047842        1.02979         5.679865   \n",
       "\n",
       "      Recall_macro  \n",
       "0        19.960000  \n",
       "1        21.330000  \n",
       "2        20.310000  \n",
       "Mean     20.533333  \n",
       "STD       0.581167  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kfold Metrics\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision_wt</th>\n",
       "      <th>Recall_wt</th>\n",
       "      <th>F-score_wt</th>\n",
       "      <th>Precision_macro</th>\n",
       "      <th>Recall_macro</th>\n",
       "      <th>F-score_macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>99.809998</td>\n",
       "      <td>99.809998</td>\n",
       "      <td>99.809998</td>\n",
       "      <td>98.479996</td>\n",
       "      <td>85.099998</td>\n",
       "      <td>91.070000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>99.809998</td>\n",
       "      <td>99.809998</td>\n",
       "      <td>99.800003</td>\n",
       "      <td>98.699997</td>\n",
       "      <td>84.720001</td>\n",
       "      <td>90.879997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>99.800003</td>\n",
       "      <td>99.809998</td>\n",
       "      <td>99.800003</td>\n",
       "      <td>98.220001</td>\n",
       "      <td>84.949997</td>\n",
       "      <td>90.879997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>99.809998</td>\n",
       "      <td>99.809998</td>\n",
       "      <td>99.809998</td>\n",
       "      <td>98.680000</td>\n",
       "      <td>86.529999</td>\n",
       "      <td>92.059998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>99.800003</td>\n",
       "      <td>99.809998</td>\n",
       "      <td>99.800003</td>\n",
       "      <td>98.489998</td>\n",
       "      <td>85.909996</td>\n",
       "      <td>91.589996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>99.806000</td>\n",
       "      <td>99.809998</td>\n",
       "      <td>99.804001</td>\n",
       "      <td>98.513998</td>\n",
       "      <td>85.441998</td>\n",
       "      <td>91.295998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STD</th>\n",
       "      <td>0.004896</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004896</td>\n",
       "      <td>0.173389</td>\n",
       "      <td>0.675733</td>\n",
       "      <td>0.462021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Precision_wt  Recall_wt  F-score_wt  Precision_macro  Recall_macro  \\\n",
       "0        99.809998  99.809998   99.809998        98.479996     85.099998   \n",
       "1        99.809998  99.809998   99.800003        98.699997     84.720001   \n",
       "2        99.800003  99.809998   99.800003        98.220001     84.949997   \n",
       "3        99.809998  99.809998   99.809998        98.680000     86.529999   \n",
       "4        99.800003  99.809998   99.800003        98.489998     85.909996   \n",
       "Mean     99.806000  99.809998   99.804001        98.513998     85.441998   \n",
       "STD       0.004896   0.000000    0.004896         0.173389      0.675733   \n",
       "\n",
       "      F-score_macro  \n",
       "0         91.070000  \n",
       "1         90.879997  \n",
       "2         90.879997  \n",
       "3         92.059998  \n",
       "4         91.589996  \n",
       "Mean      91.295998  \n",
       "STD        0.462021  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MultiClassMetrics.baseline_metrics(X, Y, rfc_model)\n",
    "\n",
    "cv_rfc = MultiClassMetrics.cv_validation(X, Y, rfc_model)\n",
    "print(\"CV Metrics\")\n",
    "display(cv_rfc)\n",
    "\n",
    "kf_rfc = MultiClassMetrics.kfold_validation(X, Y, rfc_model)\n",
    "print(\"Kfold Metrics\")\n",
    "display(kf_rfc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Older Build\n",
    "\n",
    "Use for reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Importing Labeled Data\n",
    "\n",
    "Labeled data is stored in the database `oasis-dev` in the table `clean.xspoc`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Setuo the query\n",
    "failure_wells = ['Cade 12-19HA', 'Cook 12-13 6B', 'Helling Trust 43-22 16T3',\n",
    "                'Helling Trust 44-22 5B', 'Johnsrud 5198 14-18 13T',\n",
    "                'Johnsrud 5198 14-18 15TX', 'Rolfson N 5198 12-17 5T',\n",
    "                'Rolfson N 5198 12-17 7T', 'Rolfson S 5198 11-29 2TX',\n",
    "                'Rolfson S 5198 11-29 4T', 'Rolfson S 5198 12-29 8T',\n",
    "                'Rolfson S 5198 14-29 11T', 'Stenehjem 14X-9HA']\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    \"NodeID\",\n",
    "    \"Date\",\n",
    "    \"cardPPRL\",\n",
    "    \"cardMPRL\",\n",
    "    \"PPRL\",\n",
    "    \"MPRL\",\n",
    "    \"NetProd\",\n",
    "    \"FluidLoadonPump\",\n",
    "    \"PumpIntakePressure\",\n",
    "    \"FailureBin\",\n",
    "    \"FailureLabel\"\n",
    "FROM\n",
    "    clean.xspoc\n",
    "WHERE\n",
    "    \"NodeID\" in {}\n",
    "ORDER BY\n",
    "    \"NodeID\", \"Date\";\n",
    "\"\"\".format(tuple(failure_wells))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "with lib_aws.PostgresRDS(db='oasis-dev') as engine:\n",
    "    data = pd.read_sql(query, engine, parse_dates=['Date'])\n",
    "    \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data = data[data.Date < t]\n",
    "data.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data.groupby(['NodeID']).agg({\"Date\": [min, max, \"count\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Modifying data for intern project\n",
    "\n",
    "data.rename(columns={\"NodeID\": \"WellName\", \"FailureBin\":\"BinaryLabel\", \"FailureLabel\":\"MultiLabel\"}, inplace=True)\n",
    "wells = data.WellName.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "new_wells = [\"Well \" + i for i in list('ABCDEFGHIJKLM')]\n",
    "well_map = dict(zip(wells, new_wells))\n",
    "\n",
    "data.WellName = data.WellName.map(well_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data.MultiLabel.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data.set_index(\"Date\").to_csv(\"sample_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Generate Windows\n",
    "\"\"\"\n",
    "\n",
    "def window_func(df, window):\n",
    "    \"\"\"\n",
    "    Generate MultiLabel windows\n",
    "    0 = Does not fail\n",
    "    'Label' = Actual Failure or Fails in the next n window\n",
    "    :param df: DataFrame with a single well, the Timestamp col should be the index\n",
    "    :param window: Window Value\n",
    "    \"\"\"\n",
    "    \n",
    "    df['WinLabel'] = 'Normal'  # Initialize it with 0\n",
    "    \n",
    "    mask_ = df.index >= (df.index.max() - pd.Timedelta(window))  \n",
    "    df.loc[mask_, 'WinLabel'] = -1  # Will eliminate the final window fn\n",
    "    \n",
    "    # Iterate over all the labels\n",
    "    for code in df.loc[df.FailureBin == 1, 'FailureLabel'].unique():\n",
    "        \n",
    "         # dates where that code occurs\n",
    "        code_dates = df[df.FailureLabel == code].index\n",
    "        # print(code)\n",
    "\n",
    "        # counter\n",
    "        c = 0\n",
    "\n",
    "        # iterate over these dates\n",
    "        for t in code_dates:\n",
    "            if c == 0:\n",
    "                bool_ = (df.index < code_dates[c]) & (df.index >= (code_dates[c] - pd.Timedelta(window)))\n",
    "                df.loc[bool_, 'WinLabel'] = code\n",
    "            else:\n",
    "                bool_ = (df.index < code_dates[c]) & (df.index >= (code_dates[c] - pd.Timedelta(window))) & (\n",
    "                        df.index > code_dates[c - 1])\n",
    "                df.loc[bool_, 'WinLabel'] = code\n",
    "            c = c + 1\n",
    "\n",
    "        df.loc[df.FailureLabel == code, 'WinLabel'] = code\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Function for Moving AVGs\n",
    "\"\"\"\n",
    "\n",
    "def get_ma(df, cols, freq):\n",
    "    \"\"\"\n",
    "    Rolling Values\n",
    "    :param df: DataFrame\n",
    "    :param cols: Columns which are being Rolled\n",
    "    :param freq: Rolling Window( example: 7D)\n",
    "    :return: DataFrame with Rolled Values\n",
    "    \"\"\"\n",
    "    for i in cols:\n",
    "        col_name_1 = i + '_MA'\n",
    "        df[col_name_1] = df[i].rolling(freq).mean()\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "rol_cols = [\n",
    "    \"cardPPRL\",\n",
    "    \"cardMPRL\",\n",
    "    \"PPRL\",\n",
    "    \"MPRL\",\n",
    "    \"NetProd\",\n",
    "    \"FluidLoadonPump\",\n",
    "    \"PumpIntakePressure\"\n",
    "]\n",
    "frames = []\n",
    "\n",
    "for well in data.NodeID.unique():\n",
    "    print(\"Well: {}\".format(well))\n",
    "    \n",
    "    tempdf = data[data.NodeID == well]\n",
    "    tempdf.set_index(\"Date\", inplace=True)\n",
    "    \n",
    "    tempdf = window_func(tempdf, '3 days')\n",
    "    tempdf = get_ma(tempdf, rol_cols, '7D')\n",
    "    tempdf.reset_index(inplace=True)\n",
    "    frames.append(tempdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data = pd.concat(frames)  # creeating a train df\n",
    "train_data = train_data[train_data.WinLabel != -1]\n",
    "train_data.sort_values(by=['NodeID', 'Date'], inplace=True)\n",
    "\n",
    "print(\"Null Value Distribution\")\n",
    "display(train_data.isnull().sum(axis=0))\n",
    "\n",
    "print(\"Wells\")\n",
    "display(train_data.NodeID.value_counts())\n",
    "\n",
    "print(\"Labels\")\n",
    "display(train_data.WinLabel.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Plotting\n",
    "\"\"\"\n",
    "col = 'NetProd_MA'\n",
    "well = 'Helling Trust 43-22 16T3'\n",
    "\n",
    "well_df = train_data[train_data.NodeID == well]\n",
    "# well_df.loc[well_df.FailureBin == 1, [col, 'WinLabel']] = np.nan  # Nan where Failures are present\n",
    "fig, ax = plt.subplots(figsize=(25,8))\n",
    "\n",
    "ax.plot(well_df.Date, well_df[col], label=col)\n",
    "bool_ = (well_df.WinLabel != 'Normal')\n",
    "\n",
    "ax.scatter(well_df.loc[bool_, \"Date\"], well_df.loc[bool_, col], c='r', label='Failure')\n",
    "\n",
    "ax.set_xlabel(\"Date\")\n",
    "ax.set_ylabel(\"KPI\")\n",
    "ax.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# # Droping Failure Data Point\n",
    "# train_data[train_data.FailureBin == 1]\n",
    "\n",
    "feature_cols = ['PPRL_MA', 'MPRL_MA', 'NetProd','FluidLoadonPump_MA', 'PumpIntakePressure_MA']\n",
    "add_cols=feature_cols + ['NodeID', 'Date', 'WinLabel']\n",
    "final_train = train_data[add_cols].dropna()\n",
    "final_train.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Features\n",
    "X = final_train[feature_cols]\n",
    "Y = final_train.WinLabel\n",
    "\n",
    "print(\"Feature df\")\n",
    "display(X.head())\n",
    "\n",
    "print(\"Labels Being Predicted\")\n",
    "display(Y.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Algo Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Model 1\n",
    "Random Forest classifier\n",
    "\"\"\"\n",
    "\n",
    "def build_rfc_model():\n",
    "    \"\"\"\n",
    "    Define A Random Forrest Classifier Model\n",
    "    :return: RFC Model\n",
    "    \"\"\"\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    rfc_params = {\n",
    "        'n_estimators': 100,\n",
    "        'min_samples_split': 2,\n",
    "        'min_samples_leaf': 1,\n",
    "        'class_weight': 'balanced',\n",
    "        'verbose': 0,\n",
    "        'max_features': 'auto',\n",
    "        'max_depth': None,\n",
    "    }\n",
    "\n",
    "    rfc = RandomForestClassifier(**rfc_params)\n",
    "\n",
    "    model = Pipeline([\n",
    "        ('scaler', scaler),\n",
    "        ('rfc', rfc)\n",
    "    ])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "rfc_model = build_rfc_model()\n",
    "rfc_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "MultiClassMetrics.baseline_metrics(X, Y, rfc_model)\n",
    "\n",
    "cv_rfc = MultiClassMetrics.cv_validation(X, Y, rfc_model)\n",
    "print(\"CV Metrics\")\n",
    "display(cv_rfc)\n",
    "\n",
    "kf_rfc = MultiClassMetrics.kfold_validation(X, Y, rfc_model)\n",
    "print(\"Kfold Metrics\")\n",
    "display(kf_rfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Model 2\n",
    "Gradient Boosted Classifier with Oversampling\n",
    "\"\"\"\n",
    "\n",
    "def build_gbc_model(y):\n",
    "    # Building Smote dict\n",
    "    max_count = int(y.value_counts()[0] / 3)\n",
    "    class_list = list(y.value_counts().index)\n",
    "    class_list.remove('Normal')\n",
    "    smote_dict = {key: max_count for key in class_list}\n",
    "    print(smote_dict)\n",
    "\n",
    "    # Define the model pipeline\n",
    "    scaler = StandardScaler()\n",
    "    smote = SMOTE(sampling_strategy=smote_dict, random_state=42)\n",
    "    baseline_param = {\n",
    "        'n_estimators': 4,\n",
    "        'max_depth': 8,\n",
    "        'learning_rate': 0.1,\n",
    "        'loss': 'deviance',\n",
    "        'min_samples_split': 2,\n",
    "        'verbose': 0\n",
    "    }\n",
    "\n",
    "    gbc = GradientBoostingClassifier(**baseline_param)\n",
    "\n",
    "    model = Pipeline([\n",
    "        ('scaler', scaler),\n",
    "        ('smote', smote),\n",
    "        ('gbc', gbc)\n",
    "    ])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "gbc_model = build_gbc_model(Y)\n",
    "gbc_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "MultiClassMetrics.baseline_metrics(X, Y, gbc_model)\n",
    "\n",
    "cv_rfc = MultiClassMetrics.cv_validation(X, Y, gbc_model)\n",
    "print(\"CV Metrics\")\n",
    "display(cv_rfc)\n",
    "\n",
    "kf_rfc = MultiClassMetrics.kfold_validation(X, Y, gbc_model)\n",
    "print(\"Kfold Metrics\")\n",
    "display(kf_rfc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Making Predictions on the entire dataset\n",
    "\n",
    "- Task Done for showing quick results in the dashboard\n",
    "- All wells used in the training set.\n",
    "- These same values are used in predictions as well\n",
    "- Visually when ploted the results will be, how we expect our results to look\n",
    "- Take the predictions with a big grain of salt\n",
    "\n",
    "\n",
    "### Prediciton Table\n",
    "\n",
    "The Results are added to a prediciton table in the 'oasis-dev' database.\n",
    "\n",
    "Following Columns will be present in the `clean.win_predictons` table:\n",
    "- NodeID\n",
    "- Date\n",
    "- FailureProb\n",
    "- Prob1 \n",
    "- Prob2\n",
    "- Prob3\n",
    "\n",
    "WIll use a basic rfc model and for features we use the following 7-day Moving Averages\n",
    "- PPRL_MA\n",
    "- MPRL_MA\n",
    "- FluidloadonPump_MA\n",
    "- PumpIntakePressure_MA\n",
    "\n",
    "This combination gave the best results in the tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# import the entire dataset with the columns we need for making predictions and the failrue info\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT\n",
    "    \"NodeID\",\n",
    "    \"Date\",\n",
    "    \"PPRL\",\n",
    "    \"MPRL\",\n",
    "    \"NetProd\",\n",
    "    \"FluidLoadonPump\",\n",
    "    \"PumpIntakePressure\",\n",
    "    \"FailureBin\",\n",
    "    \"FailureLabel\"\n",
    "FROM\n",
    "    clean.xspoc\n",
    "ORDER BY\n",
    "    \"NodeID\", \"Date\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "with lib_aws.PostgresRDS(db='oasis-dev') as engine:\n",
    "    data = pd.read_sql(query, engine, parse_dates=['Date'])\n",
    "    \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Generating Features\n",
    "rol_cols = [\n",
    "    \"PPRL\",\n",
    "    \"MPRL\",\n",
    "    \"NetProd\",\n",
    "    \"FluidLoadonPump\",\n",
    "    \"PumpIntakePressure\"\n",
    "]\n",
    "frames = []\n",
    "\n",
    "for well in data.NodeID.unique():\n",
    "    print(\"Well: {}\".format(well))\n",
    "    \n",
    "    tempdf = data[data.NodeID == well]\n",
    "    tempdf.set_index(\"Date\", inplace=True)\n",
    "    \n",
    "    tempdf = window_func(tempdf, '3 days')\n",
    "    tempdf = get_ma(tempdf, rol_cols, '7D')\n",
    "    tempdf.reset_index(inplace=True)\n",
    "    frames.append(tempdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_data = pd.concat(frames)  # creeating a train df\n",
    "train_data = train_data[train_data.WinLabel != -1]\n",
    "train_data.sort_values(by=['NodeID', 'Date'], inplace=True)\n",
    "\n",
    "print(\"Null Value Distribution\")\n",
    "display(train_data.isnull().sum(axis=0))\n",
    "\n",
    "print(\"Wells\")\n",
    "display(train_data.NodeID.value_counts())\n",
    "\n",
    "print(\"Labels\")\n",
    "display(train_data.WinLabel.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# # Droping Failure Data Point\n",
    "# train_data[train_data.FailureBin == 1]\n",
    "\n",
    "feature_cols = ['PPRL_MA', 'MPRL_MA', 'NetProd_MA','FluidLoadonPump_MA', 'PumpIntakePressure_MA']\n",
    "add_cols=feature_cols + ['NodeID', 'Date', 'WinLabel']\n",
    "final_train = train_data[add_cols].dropna()\n",
    "final_train.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Features\n",
    "X = final_train[feature_cols]\n",
    "Y = final_train.WinLabel\n",
    "\n",
    "print(\"Feature df\")\n",
    "display(X.head())\n",
    "\n",
    "print(\"Labels Being Predicted\")\n",
    "display(Y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# quick test\n",
    "rfc_model = build_rfc_model()\n",
    "display(rfc_model)\n",
    "\n",
    "MultiClassMetrics.baseline_metrics(X, Y, rfc_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Fit the whole df \n",
    "rfc_model = build_rfc_model()\n",
    "rfc_model.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Predictions\n",
    "\"\"\"\n",
    "print(\"Classes Predicted {}\".format(rfc_model.classes_))\n",
    "y_hat = rfc_model.predict(X.to_numpy())                                          # Get predictions\n",
    "y_prob = rfc_model.predict_proba(X.to_numpy()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ind = final_train.index\n",
    "data_pred = final_train[[\"NodeID\", \"Date\"]]\n",
    "data_pred.loc[ind, 'PredClass'] = y_hat \n",
    "\n",
    "pred_classes = rfc_model.classes_\n",
    "\n",
    "for i in range(np.shape(pred_classes)[0]):\n",
    "    print(i)\n",
    "    col = 'Prob ' + str(pred_classes[i])\n",
    "    data_pred.loc[ind, col] = y_prob[:, i] * 100\n",
    "data_pred = data_pred.round(3)\n",
    "data_pred['FailureProb'] = 100 - data_pred['Prob Normal']\n",
    "data_pred.drop(columns='Prob Normal', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Adding Prob data to DF\n",
    "\"\"\"\n",
    "\n",
    "# Replace the full bounds df\n",
    "lib_aws.AddData.add_data(df=data_pred, db='oasis-dev', table='xpred', schema='clean',\n",
    "                         merge_type='replace', card_col=None, index_col='Date')\n",
    "\n",
    "# Update index on pred table in database\n",
    "with lib_aws.PostgresRDS(db='oasis-dev') as engine:\n",
    "    with engine.begin() as connection:\n",
    "        connection.execute(\"\"\"CREATE UNIQUE INDEX xpred_idx ON clean.xpred (\"NodeID\", \"Date\");\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
